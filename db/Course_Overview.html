<!DOCTYPE html>
<html>
<head>
  <meta name="databricks-html-version" content="1">
<title>Course_Overview - Databricks</title>

<meta charset="utf-8">
<meta name="google" content="notranslate">
<meta http-equiv="Content-Language" content="en">
<meta http-equiv="Content-Type" content="text/html; charset=UTF8">
<link rel="stylesheet"
  href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700">

<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201606222113370000-29e64bf9afe1117763a990704253c3678448e6c5/lib/css/bootstrap.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201606222113370000-29e64bf9afe1117763a990704253c3678448e6c5/lib/jquery-ui-bundle/jquery-ui.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201606222113370000-29e64bf9afe1117763a990704253c3678448e6c5/css/main.css">
<link rel="stylesheet" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201606222113370000-29e64bf9afe1117763a990704253c3678448e6c5/css/print.css" media="print">
<link rel="icon" type="image/png" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201606222113370000-29e64bf9afe1117763a990704253c3678448e6c5/img/favicon.ico"/>
<script>window.settings = {"enableAutoCompleteAsYouType":[],"devTierName":"Community Edition","workspaceFeaturedLinks":[{"linkURI":"https://docs.cloud.databricks.com/docs/latest/databricks_guide/index.html","displayName":"Databricks Guide","icon":"question"},{"linkURI":"https://docs.cloud.databricks.com/docs/latest/sample_applications/index.html","displayName":"Application Examples","icon":"code"},{"linkURI":"https://docs.cloud.databricks.com/docs/latest/courses/index.html","displayName":"Training","icon":"graduation-cap"}],"dbcForumURL":"http://forums.databricks.com/","nodeInfo":{"node_types":[{"spark_heap_memory":4800,"instance_type_id":"r3.2xlarge","spark_core_oversubscription_factor":3.0,"node_type_id":"class-node","description":"Class Node","container_memory_mb":6000,"memory_mb":6144,"num_cores":0.88}],"default_node_type_id":"class-node"},"enableThirdPartyApplicationsUI":false,"enableClusterAcls":true,"notebookRevisionVisibilityHorizon":0,"enableTableHandler":true,"isAdmin":false,"enableLargeResultDownload":true,"zoneInfos":[{"id":"us-west-2a","isDefault":true},{"id":"us-west-2c","isDefault":false},{"id":"us-west-2b","isDefault":false}],"enablePublishNotebooks":false,"enableJobAclsConfig":true,"enableFullTextSearch":true,"enableElasticSparkUI":false,"allowRunOnPendingClusters":true,"applications":false,"fileStoreBase":"FileStore","configurableSparkOptionsSpec":[{"keyPattern":"spark\\.kryo(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.kryo.*","valuePatternDisplay":"*","description":"Configuration options for Kryo serialization"},{"keyPattern":"spark\\.io\\.compression\\.codec","valuePattern":"(lzf|snappy|org\\.apache\\.spark\\.io\\.LZFCompressionCodec|org\\.apache\\.spark\\.io\\.SnappyCompressionCodec)","keyPatternDisplay":"spark.io.compression.codec","valuePatternDisplay":"snappy|lzf","description":"The codec used to compress internal data such as RDD partitions, broadcast variables and shuffle outputs."},{"keyPattern":"spark\\.serializer","valuePattern":"(org\\.apache\\.spark\\.serializer\\.JavaSerializer|org\\.apache\\.spark\\.serializer\\.KryoSerializer)","keyPatternDisplay":"spark.serializer","valuePatternDisplay":"org.apache.spark.serializer.JavaSerializer|org.apache.spark.serializer.KryoSerializer","description":"Class to use for serializing objects that will be sent over the network or need to be cached in serialized form."},{"keyPattern":"spark\\.rdd\\.compress","valuePattern":"(true|false)","keyPatternDisplay":"spark.rdd.compress","valuePatternDisplay":"true|false","description":"Whether to compress serialized RDD partitions (e.g. for StorageLevel.MEMORY_ONLY_SER). Can save substantial space at the cost of some extra CPU time."},{"keyPattern":"spark\\.speculation","valuePattern":"(true|false)","keyPatternDisplay":"spark.speculation","valuePatternDisplay":"true|false","description":"Whether to use speculation (recommended off for streaming)"},{"keyPattern":"spark\\.es(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"es(\\.([^\\.]+))+","valuePattern":".*","keyPatternDisplay":"es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"spark\\.(storage|shuffle)\\.memoryFraction","valuePattern":"0?\\.0*([1-9])([0-9])*","keyPatternDisplay":"spark.(storage|shuffle).memoryFraction","valuePatternDisplay":"(0.0,1.0)","description":"Fraction of Java heap to use for Spark's shuffle or storage"},{"keyPattern":"spark\\.streaming\\.backpressure\\.enabled","valuePattern":"(true|false)","keyPatternDisplay":"spark.streaming.backpressure.enabled","valuePatternDisplay":"true|false","description":"Enables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process. Internally, this dynamically sets the maximum receiving rate of receivers. This rate is upper bounded by the values `spark.streaming.receiver.maxRate` and `spark.streaming.kafka.maxRatePerPartition` if they are set."},{"keyPattern":"spark\\.streaming\\.receiver\\.maxRate","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.receiver.maxRate","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which each receiver will receive data. Effectively, each stream will consume at most this number of records per second. Setting this configuration to 0 or a negative number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for mode details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRatePerPartition","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRatePerPartition","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which data will be read from each Kafka partition when using the Kafka direct stream API introduced in Spark 1.3. See the Kafka Integration guide for more details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRetries","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRetries","valuePatternDisplay":"numeric","description":"Maximum number of consecutive retries the driver will make in order to find the latest offsets on the leader of each partition (a default value of 1 means that the driver will make a maximum of 2 attempts). Only applies to the Kafka direct stream API introduced in Spark 1.3."},{"keyPattern":"spark\\.streaming\\.ui\\.retainedBatches","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.ui.retainedBatches","valuePatternDisplay":"numeric","description":"How many batches the Spark Streaming UI and status APIs remember before garbage collecting."}],"enableReactNotebookComments":true,"enableResetPassword":true,"enableJobsSparkUpgrade":true,"sparkVersions":[{"key":"1.6.x-ubuntu15.10","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-1.6.1-hadoop1-jenkins-ip-10-30-10-144-U29e64bf9af-S2368283920-2016-06-23-00:19:57.707639","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.4.x-ubuntu15.10","displayName":"Spark 1.4.1 (Hadoop 1)","packageLabel":"spark-1.4-jenkins-ip-10-30-10-144-U29e64bf9af-S9c254ab12a-2016-06-23-00:19:57.707639","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"master","displayName":"Spark master (dev)","packageLabel":"","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.6.x-ubuntu15.10-hadoop1","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-1.6.1-hadoop1-jenkins-ip-10-30-10-144-U29e64bf9af-S2368283920-2016-06-23-00:19:57.707639","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.6.1-ubuntu15.10-hadoop1","displayName":"Spark 1.6.1 (Hadoop 1)","packageLabel":"spark-1.6.1-hadoop1-jenkins-ip-10-30-10-144-U29e64bf9af-S2368283920-2016-06-23-00:19:57.707639","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.1-ubuntu15.10-hadoop2","displayName":"Spark 1.6.1 (Hadoop 2)","packageLabel":"spark-1.6.1-hadoop2-jenkins-ip-10-30-10-144-U29e64bf9af-S2368283920-2016-06-23-00:19:57.707639","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.5.x-ubuntu15.10","displayName":"Spark 1.5.2 (Hadoop 1)","packageLabel":"spark-1.5-jenkins-ip-10-30-10-144-U29e64bf9af-S9ca52d000d-2016-06-23-00:19:57.707639","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.3.x-ubuntu15.10","displayName":"Spark 1.3.0 (Hadoop 1)","packageLabel":"spark-1.3-jenkins-ip-10-30-10-144-U29e64bf9af-Sa2ee4664b2-2016-06-23-00:19:57.707639","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.x-ubuntu15.10","displayName":"Spark 2.0 (apache/branch-2.0 preview)","packageLabel":"spark-image-1e373018dd5d67adc815234c23e8d1e9eca5394f90f8f2a00df56e2c182e0ad7","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.0-ubuntu15.10","displayName":"Spark 1.6.0 (Hadoop 1)","packageLabel":"spark-1.6.0-jenkins-ip-10-30-10-144-U29e64bf9af-Sf90f83597b-2016-06-23-00:19:57.707639","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.x-ubuntu15.10-hadoop2","displayName":"Spark 1.6.x (Hadoop 2)","packageLabel":"spark-1.6.1-hadoop2-jenkins-ip-10-30-10-144-U29e64bf9af-S2368283920-2016-06-23-00:19:57.707639","upgradable":true,"deprecated":false,"customerVisible":false}],"enableRestrictedClusterCreation":false,"enableFeedback":false,"enableClusterAutoScaling":false,"defaultNumWorkers":8,"serverContinuationTimeoutMillis":10000,"driverStderrFilePrefix":"stderr","enableNotebookRefresh":false,"driverStdoutFilePrefix":"stdout","enableSparkDocsSearch":true,"sparkHistoryServerEnabled":true,"sanitizeMarkdownHtml":true,"enableIPythonImportExport":true,"enableNotebookHistoryDiffing":true,"branch":"2.22.1","accountsLimit":-1,"enableNotebookGitBranching":true,"local":false,"enableStrongPassword":false,"displayDefaultContainerMemoryGB":6,"deploymentMode":"production","useSpotForWorkers":true,"enableUserInviteWorkflow":false,"enableStaticNotebooks":true,"enableCssTransitions":true,"showHomepageFeaturedLinks":true,"pricingURL":"https://databricks.com/product/pricing","enableClusterAclsConfig":true,"notifyLastLogin":false,"enableNotebookGitVersioning":true,"files":"files/","enableDriverLogsUI":true,"disableLegacyDashboards":false,"enableWorkspaceAclsConfig":true,"dropzoneMaxFileSize":4096,"enableNewDashboardViews":true,"driverLog4jFilePrefix":"log4j","enableSingleSignOn":true,"enableMavenLibraries":true,"displayRowLimit":1000,"defaultSparkVersion":{"key":"1.6.1-ubuntu15.10-hadoop1","displayName":"Spark 1.6.1 (Hadoop 1)","packageLabel":"spark-1.6.1-hadoop1-jenkins-ip-10-30-10-144-U29e64bf9af-S2368283920-2016-06-23-00:19:57.707639","upgradable":true,"deprecated":false,"customerVisible":true},"enableMountAclsConfig":false,"enableClusterAclsByTier":true,"disallowAddingAdmins":false,"enableSparkConfUI":true,"featureTier":"UNKNOWN_TIER","enableOrgSwitcherUI":false,"clustersLimit":-1,"enableJdbcImport":true,"logfiles":"logfiles/","enableWebappSharding":false,"enableClusterDeltaUpdates":true,"enableSingleSignOnLogin":false,"useFixedStaticNotebookVersionForDevelopment":false,"enableMountAcls":false,"requireEmailUserName":true,"enableDashboardViews":false,"dbcFeedbackURL":"http://feedback.databricks.com/forums/263785-product-feedback","enableMountAclService":true,"enableWorkspaceAclService":true,"enableWorkspaceAcls":true,"gitHash":"29e64bf9afe1117763a990704253c3678448e6c5","showWorkspaceFeaturedLinks":true,"signupUrl":"https://databricks.com/try-databricks","allowFeedbackForumAccess":true,"enableImportFromUrl":true,"enableMiniClusters":false,"showDevTierBetaVersion":false,"enableDebugUI":false,"allowNonAdminUsers":true,"enableSingleSignOnByTier":false,"staticNotebookResourceUrl":"https://databricks-prod-cloudfront.cloud.databricks.com/static/201606222113370000-29e64bf9afe1117763a990704253c3678448e6c5/","enableSparkPackages":true,"dynamicSparkVersions":true,"enableNotebookHistoryUI":true,"showDebugCounters":false,"enableFolderHtmlExport":true,"enableSparkVersionsUI":true,"homepageFeaturedLinks":[{"linkURI":"https://docs.cloud.databricks.com/docs/latest/featured_notebooks/A%20Gentle%20Introduction%20to%20Apache%20Spark%20on%20Databricks.html","displayName":"Introduction to Apache Spark on Databricks","icon":"img/home/Python_icon.svg"},{"linkURI":"https://docs.cloud.databricks.com/docs/latest/featured_notebooks/Quick%20Start%20DataFrames.html","displayName":"Quick Start DataFrames","icon":"img/home/Scala_icon.svg"},{"linkURI":"https://docs.cloud.databricks.com/docs/latest/featured_notebooks/GSW%20Passing%20Analysis%20(new).html","displayName":"GSW Passing Analysis (new)","icon":"img/home/Python_icon.svg"}],"upgradeURL":"","notebookLoadingBackground":"#fff","enableServerAutoComplete":true,"enableStaticHtmlImport":true,"enableTerminal":false,"defaultMemoryPerContainerMB":6000,"enablePresenceUI":true,"accounts":false,"useFramedStaticNotebooks":true,"enableNewProgressReportUI":true,"defaultCoresPerContainer":4};</script>
<script>var __DATABRICKS_NOTEBOOK_MODEL = {"version":"NotebookV1","origId":112755,"name":"Course_Overview","language":"scala","commands":[{"version":"CommandV1","origId":112757,"guid":"5053b89c-a85d-4f05-a683-441fea017aa0","subtype":"command","commandType":"auto","position":1.0,"command":"%md\nScalable Data Science - Course Overview\n=======\n\nScalable data science is a technical course in the area of Big Data, aimed at the needs of the\nemerging data industry in Christchurch and those of certain academic domain experts across\nUniversity of Canterbury's Colleges, including, Arts, Science and Engineering. This course uses\nApache Spark, a fast and general engine for large-scale data processing via databricks to compute\nwith datasets that won't fit in a single computer. The course will introduce Spark?s core concepts\nvia hands-on coding, including resilient distributed datasets and map-reduce algorithms, DataFrame\nand Spark SQL on Catalyst, scalable machine-learning pipelines in MlLib and vertex programs using\nthe distributed graph processing framework of GraphX. We will solve instances of real-world big data\ndecision problems from various scientific domains.\n\nThis is being prepared by Raazesh Sainudiin and Sivanand Sivaram\nwith assistance from Paul Brouwers, Dillon George and Ivan Sadikov.\n\nAll course projects by seven enrolled and four observing students for Semester 1 of 2016 at UC, Ilam are part of this content.\n\n## How to self-learn this content?\n\nThe 2016 instance of this [scalable-data-science course](http://www.math.canterbury.ac.nz/~r.sainudiin/courses/ScalableDataScience/) finished on June 30 2016.\n\nTo learn Apache Spark for free try **databricks Community edition** by starting from [https://databricks.com/try-databricks](https://databricks.com/try-databricks).\n\nAll course content can be uploaded for self-paced learning by copying the following [URL for 2016/Spark1_6_to_1_3/scalable-data-science.dbc archive](https://raw.githubusercontent.com/raazesh-sainudiin/scalable-data-science/master/dbcArchives/2016/Spark1_6_to_1_3/scalable-data-science.dbc)\nand importing it from the URL to your [free Databricks Community Edition](https://community.cloud.databricks.com).\n\nThe Gitbook version of this content is [https://www.gitbook.com/book/raazesh-sainudiin/scalable-data-science/details](https://www.gitbook.com/book/raazesh-sainudiin/scalable-data-science/details).\n\n## Contribute\n\nAll course content is currently being pushed by Raazesh Sainudiin after it has been tested in\nDatabricks cloud (mostly under Spark 1.6 and some involving Magellan under Spark 1.5.1).\n\nThe markdown version for `gitbook` is generated from the Databricks `.scala` and other source codes.\nThe gitbook version will lag behind the Databricks version available in the Databricks cloud. The following issues need to be resolved:\n\n* dialects of Tex between databricks and github are different (need to babel out into github-compatible tex from databricks compatible tex)\n* need to find a stable solution for the output of various databricks cells to be shown in gitbook, including those from `display_HTML` and `frameIt` with their in-place embeds of web content.\n\nPlease feel free to fork the github repository:\n\n* [https://github.com/raazesh-sainudiin/scalable-data-science](https://github.com/raazesh-sainudiin/scalable-data-science).\n\nUnfortunately, pull requests cannot be accepted until the end of June 2016 when the course completes\nalong with the course projects.\n\nFurthermore, due to the anticipation of Spark 2.0 this mostly Spark 1.6 version could be enhanced with a 2.0 version-specific upgrade.\n\nPlease send any typos or suggestions to raazesh.sainudiin@gmail.com\n\nPlease read a note on [babel](https://github.com/raazesh-sainudiin/scalable-data-science/blob/master/babel/README.md) to understand how the gitbook is generated from the `.scala` source of the databricks notebook.\n\n## How to cite this work?\n\nScalable Data Science, Raazesh Sainudiin and Sivanand Sivaram, Published by GitBook [https://www.gitbook.com/book/raazesh-sainudiin/scalable-data-science/details](https://www.gitbook.com/book/raazesh-sainudiin/scalable-data-science/details), 787 pages, 30th June 2016.\n\n## Supported By\n[Databricks Academic Partners Program](https://databricks.com/academic) and [Amazon Web Services Educate](https://www.awseducate.com/microsite/CommunitiesEngageHome).\n\nRaazesh Sainudiin,\nLaboratory for Mathematical Statistical Experiments, Christchurch Centre\nand School of Mathematics and Statistics,\nUniversity of Canterbury,\nPrivate Bag 4800,\nChristchurch 8041,\nAotearoa New Zealand\n\nSun Jun 19 21:59:19 NZST 2016\n","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"a81b4977-152d-4fb3-abd4-e08513a7be14"},{"version":"CommandV1","origId":112758,"guid":"7feebed4-dad5-4a1f-84c7-b2567ce9b3d6","subtype":"command","commandType":"auto","position":2.0,"command":"%md\n\n# Summary\n\nNote: these links need to be updated if `scalable-data-science` folder is not in `Workspace` folder.\n\n* [Prelude](#workspace/scalable-data-science/sdsBlog)\n\n* [Week 1: Introduction to Scalable Data Science](#workspace/scalable-data-science/week1)\n    * [Scalable Data Science](#workspace/scalable-data-science/week1/01_introduction/000_scalableDataScience)\n    * [Why Spark?](#workspace/scalable-data-science/week1/01_introduction/001_whySpark)\n    * [Login to databricks](#workspace/scalable-data-science/week1/01_introduction/002_loginToDatabricks)\n    * [Scala Crash Course](#workspace/scalable-data-science/week1/01_introduction/003_scalaCrashCourse)\n\n* [Week 2: Introduction to Spark RDDs, Transformations and Actions and Word Count of the US State of the Union Addresses](#workspace/scalable-data-science/week2)\n    * [RDDs, Transformations and Actions](#workspace/scalable-data-science/week2/02_SparkEssentials/004_RDDsTransformationsActions)\n    * [HOMEWORK: RDDs, Transformations and Actions](#workspace/scalable-data-science/week2/02_SparkEssentials/005_RDDsTransformationsActionsHOMEWORK)\n    * [Word Count: US State of Union Addesses](#workspace/scalable-data-science/week2/03_WordCount/006_WordCount)\n    * [EXTRA_Word Count: ETL of US State of Union Addesses](#workspace/scalable-data-science/xtraResources/sdsDatasets/scraperUSStateofUnionAddresses)\n\n* [Week 3: Introduction to Spark SQL, ETL and EDA of Diamonds, Power Plant and Wiki CLick Streams Data](#workspace/scalable-data-science/week3/)\n    * [Spark SQL Introduction](#workspace/scalable-data-science/week3/04_SparkSQLIntro/007_SparkSQLIntroBasics)\n        * [HOMEWORK: overview](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/sqlProgrammingGuide/001_overview_sqlProgGuide)\n        * [HOMEWORK: getting started](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/sqlProgrammingGuide/002_gettingStarted_sqlProgGuide)\n        * [HOMEWORK: data sources](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/sqlProgrammingGuide/003_dataSources_sqlProgGuide)\n        * [HOMEWORK: performance tuning](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/sqlProgrammingGuide/004_performanceTuning_sqlProgGuide)\n        * [HOMEWORK: distributed sql engine](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/sqlProgrammingGuide/005_distributedSqlEngine_sqlProgGuide)\n    * [ETL and EDA of Diamonds Data](#workspace/scalable-data-science/week3/05_SparkSQLETLEDA/008_DiamondsPipeline_01ETLEDA)\n    * [ETL and EDA of Power Plant Data](#workspace/scalable-data-science/week3/05_SparkSQLETLEDA/009_PowerPlantPipeline_01ETLEDA)\n    * [ETL and EDA of Wiki Click Stream Data](#workspace/scalable-data-science/week3/05_SparkSQLETLEDA/010_wikipediaClickStream_01ETLEDA)\n\n* [Week 4: Introduction to Machine Learning - Unsupervised Clustering and Supervised Classification](#workspace/scalable-data-science/week4/)\n    * [Introduction to Machine Learning](#workspace/scalable-data-science/week4/06_MLIntro/011_IntroToML)\n    * [Unsupervised Clustering of 1 Million Songs via K-Means in 3 Stages](#workspace/scalable-data-science/week4/07_UnsupervisedClusteringKMeans_1MSongs/012_1MSongsKMeans_Intro)\n        * [Stage 1: Extract-Transform-Load](#workspace/scalable-data-science/week4/07_UnsupervisedClusteringKMeans_1MSongs/013_1MSongsKMeans_Stage1ETL)\n        * [Stage 2: Explore](#workspace/scalable-data-science/week4/07_UnsupervisedClusteringKMeans_1MSongs/014_1MSongsKMeans_Stage2Explore)\n        * [Stage 3: Model](#workspace/scalable-data-science/week4/07_UnsupervisedClusteringKMeans_1MSongs/015_1MSongsKMeans_Stage3Model)\n    * [Supervised Classification of Hand-written Digits via Decision Trees](#workspace/scalable-data-science/week4/08_SupervisedLearningDecisionTrees/016_DecisionTrees_HandWrittenDigitRecognition)\n\n* [Week 5: Introduction to Non-distributed and Distributed Linear Algebra and Applied Linear Regression](#workspace/scalable-data-science/week5/)\n    * [Linear Algebra Introduction](#workspace/scalable-data-science/week5/09_LinearAlgebraIntro/017_LAlgIntro)\n        * [HOMEWORK: breeze linear algebra cheat sheet](#workspace/scalable-data-science/xtraResources/LinearAlgebra/LAlgCheatSheet)\n    * [Linear Regression Introduction](#workspace/scalable-data-science/week5/10_LinearRegressionIntro/018_LinRegIntro)\n    * [Distributed Linear Algebra for Linear Regression Introduction](#workspace/scalable-data-science/week5/10_LinearRegressionIntro/019_DistLAlgForLinRegIntro)\n        * [HOMEWORK: Spark Data Types for Distributed Linear Algebra](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/MLlibProgrammingGuide/dataTypes/000_dataTypesProgGuide)\n            * [Local Vector](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/MLlibProgrammingGuide/dataTypes/001_LocalVector)\n            * [Labeled Point](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/MLlibProgrammingGuide/dataTypes/002_LabeledPoint)\n            * [Local Matrix](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/MLlibProgrammingGuide/dataTypes/003_LocalMatrix)\n            * [Distributed Matrix](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/MLlibProgrammingGuide/dataTypes/004_DistributedMatrix)\n            * [Row Matrix](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/MLlibProgrammingGuide/dataTypes/005_RowMatrix)\n            * [Indexed Row Matrix](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/MLlibProgrammingGuide/dataTypes/006_IndexedRowMatrix)\n            * [Coordinate Matrix](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/MLlibProgrammingGuide/dataTypes/007_CoordinateMatrix)\n            * [Block Matrix](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/MLlibProgrammingGuide/dataTypes/008_BlockMatrix)\n    * [Power Plant Pipeline: Model, Tune, Evaluate](#workspace/scalable-data-science/week5/11_MLlibModelTuneEvaluate/020_PowerPlantPipeline_02ModelTuneEvaluate)\n\n* [Week 6: Introduction to Spark Streaming, Twitter Collector, Top Hashtag Counter and Streaming Model-Prediction Server](#workspace/scalable-data-science/week6/)\n    * [Introduction to Spark Streaming](#workspace/scalable-data-science/week6/12_SparkStreaming/021_SparkStreamingIntro)\n    * [Tweet Collector - broken down](#workspace/scalable-data-science/week6/12_SparkStreaming/022_TweetCollector)\n    * [Tweet Collector - Generic](#workspace/scalable-data-science/week6/12_SparkStreaming/022_TweetGenericCollector)\n    * [Tweet Hashtag Counter](#workspace/scalable-data-science/week6/12_SparkStreaming/023_TweetHashtagCount)\n    * [Streaming Model-Prediction Server, the Full Powerplant Pipeline](#workspace/scalable-data-science/week6/13_StreamingMLlib_ModelTuneEvaluateDeploy/024_PowerPlantPipeline_03ModelTuneEvaluateDeploy)\n\n* [Week 7: Probabilistic Topic Modelling via Latent Dirichlet Allocation and Intro to XML-parsing of Old Bailey Online](#workspace/scalable-data-science/week7/)\n    * [Probabilistic Topic Modelling](#workspace/scalable-data-science/week7/14_ProbabilisticTopicModels/025_LDA_20NewsGroupsSmall)\n    * [HOMEWORK: Introduction to XML-parsing of Old Bailey Online](#workspace/scalable-data-science/xtraResources/OldBaileyOnline/OBO_LoadExtract)\n\n* [Week 8: Graph Querying in GraphFrames and Distributed Vertex Programming in GraphX](#workspace/scalable-data-science/week8/)\n    * [Introduction to GraphFrames](#workspace/scalable-data-science/week8/15_GraphX/026_GraphFramesUserGuide)\n    * [HOMEWORK: On-Time Flight Performance with GraphFrames](#workspace/scalable-data-science/week8/15_GraphX/028_OnTimeFlightPerformance)\n\n* [Week 9: Deep Learning, Convolutional Neural Nets, Sparkling Water and Tensor Flow](#workspace/scalable-data-science/week9/)\n    * [Deep Learning, A Crash Introduction](#workspace/scalable-data-science/week9/16_Deep_learning/030_Deep_learning)\n    * [H2O Sparkling Water](#workspace/scalable-data-science/week9/17_SparklingWater/031_H2O_sparkling_water)\n    * [H2O Sparkling Water: Ham or Spam Example](#workspace/scalable-data-science/week9/17_SparklingWater/032_Deep_learning_ham_or_spam)\n    * [Setting up TensorFlow Spark Cluster](#workspace/scalable-data-science/week9/18_sparklingTensorFlow/033_SetupCluster_SparkTensorFlow)\n    * [Scalable Object Identification with Spark and TensorFlow](#workspace/scalable-data-science/week9/18_sparklingTensorFlow/034_SampleML_SparkTensorFlow)\n\n\n* [Week 10: Scalable Geospatial Analytics with Magellan](#workspace/scalable-data-science/week10/)\n    * [What is Scalable Geospatial Analytics](#workspace/scalable-data-science/week10/035_ScalableGeoSpatialComputing)\n    * [Introduction to Magellan for Scalable Geospatial Analytics](#workspace/scalable-data-science/week10/036_IntroductionToMagellan)\n\n* [Week 11 and 12: Student Projects](#workspace/scalable-data-science/studentProjects/)\n    * [Student Projects](#workspace/scalable-data-science/studentProjects/00_studentPresentations)\n    * [Dillon George, Scalable Geospatial Algorithms](#workspace/scalable-data-science/studentProjects/01_DillonGeorge)\n        * [Scalable Spatio-temporal Constraint Satisfaction](#workspace/scalable-data-science/studentProjects/01_DillonGeorge/037_MSR_BeijingTaxiTrajectories_MagellanQueries)\n        * [Map-matching](#workspace/scalable-data-science/studentProjects/01_DillonGeorge/038_UberMapMatchingAndVisualization)\n        * [OpenStreetMap to GraphX](#workspace/scalable-data-science/studentProjects/01_DillonGeorge/039_OSMMap2GraphX)\n    * [Akinwande Atanda, Twitter Analytics](#workspace/scalable-data-science/studentProjects/02_AkinwandeAtanda)\n        * [Chapter_Outline_and_Objectives](#workspace/scalable-data-science/studentProjects/02_AkinwandeAtanda/Tweet_Analytics/039_TA00_Chapter_Outline_and_Objectives)\n        * [Unfiltered_Tweets_Collector_Set-up](#workspace/scalable-data-science/studentProjects/02_AkinwandeAtanda/Tweet_Analytics/040_TA01_01_Unfiltered_Tweets_Collector_Set-up)\n        * [Filtered_Tweets_Collector_Set-up_by_Keywords_and_Hashtags](#workspace/scalable-data-science/studentProjects/02_AkinwandeAtanda/Tweet_Analytics/041_TA01_02_Filtered_Tweets_Collector_Set-up_by_Keywords_and_Hashtags)\n        * [Filtered_Tweets_Collector_Set-up_by_Class](#workspace/scalable-data-science/studentProjects/02_AkinwandeAtanda/Tweet_Analytics/042_TA01_03_Filtered_Tweets_Collector_Set-up_by_Class)\n        * [ETL_Tweets](#workspace/scalable-data-science/studentProjects/02_AkinwandeAtanda/Tweet_Analytics/043_TA02_ETL_Tweets)\n        * [binary_classification](#workspace/scalable-data-science/studentProjects/02_AkinwandeAtanda/Tweet_Analytics/045_TA03_02_binary_classification)\n        * [binary_classification_with_Loop](#workspace/scalable-data-science/studentProjects/02_AkinwandeAtanda/Tweet_Analytics/046_TA03_03_binary_classification_with_Loop)\n        * [binary_classification_with_Loop_TweetDataSet](#workspace/scalable-data-science/studentProjects/02_AkinwandeAtanda/Tweet_Analytics/047_TA03_04_binary_classification_with_Loop_TweetDataSet)\n\n    * [Yinnon Dolev, Deciphering Spider Vision](#workspace/scalable-data-science/studentProjects/03_YinnonDolev/048_decipheringSpiderVision)\n    * [Xin Zhao, Higher Order Spectral CLustering](#workspace/scalable-data-science/studentProjects/04_XinZhao/049_Introduction_HighOrderSpectralClustering)\n        * [Xin Zhao, Case-study](#workspace/scalable-data-science/studentProjects/04_XinZhao/050_CaseStudy_HighOrderSpectralClustering)\n    * [Shanshan Zhou](#workspace/scalable-data-science/studentProjects/05_ShanshanZhou/051_EEG_Explore)\n    * [Shakira Suwan, Change Detection in Random Graph Series](#workspace/scalable-data-science/studentProjects/06_ShakiraSuwan/052_ChangeDetectionInRandomGraphSeries)\n    * [Matthew Hendtlass, The ATP graph](#workspace/scalable-data-science/studentProjects/07_MatthewHendtlass/053_The_ATP_graph)\n        * [Yuki_Katoh_GSW_Passing_Analysis](#workspace/scalable-data-science/studentProjects/07_MatthewHendtlass/054_Yuki_Katoh_GSW_Passing_Analysis)\n    * [Andrey Konstantinov, Keystroke Biometric](#workspace/scalable-data-science/studentProjects/08_AndreyKonstantinov/055_KeystrokeBiometric)\n    * [Dominic Lee, Random Matrices](#workspace/scalable-data-science/studentProjects/09_DominicLee/056_RandomMatrices)\n        * [Dominic Lee, References](#workspace/scalable-data-science/studentProjects/09_DominicLee/057_QuickReferences)\n    * [Harry Wallace, Movie Recommender](#workspace/scalable-data-science/studentProjects/10_HarryWallace/058_MovieRecommender)\n    * [Ivan Sadikov, Reading NetFlow Logs](#workspace/scalable-data-science/studentProjects/11_IvanSadikov/059_SparkNetFlow)\n\n\n\n* [Extra Resources](#workspace/scalable-data-science/xtraResources)\n    * [AWS Educate](#workspace/scalable-data-science/xtraResources/awsEducate/sharing)\n    * Databricksified Spark SQL Programming Guide 1.6\n        * [overview](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/sqlProgrammingGuide/001_overview_sqlProgGuide)\n        * [getting started](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/sqlProgrammingGuide/002_gettingStarted_sqlProgGuide)\n        * [data sources](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/sqlProgrammingGuide/003_dataSources_sqlProgGuide)\n        * [performance tuning](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/sqlProgrammingGuide/004_performanceTuning_sqlProgGuide)\n        * [distributed sql engine](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/sqlProgrammingGuide/005_distributedSqlEngine_sqlProgGuide)\n    * [Linear Algebra Cheat Sheet](#workspace/scalable-data-science/xtraResources/LinearAlgebra/LAlgCheatSheet)\n    * Databricksified Data Types in MLLib Programming Guide 1.6\n        * [Local Vector](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/MLlibProgrammingGuide/dataTypes/001_LocalVector)\n        * [Labeled Point](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/MLlibProgrammingGuide/dataTypes/002_LabeledPoint)\n        * [Local Matrix](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/MLlibProgrammingGuide/dataTypes/003_LocalMatrix)\n        * [Distributed Matrix](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/MLlibProgrammingGuide/dataTypes/004_DistributedMatrix)\n        * [Row Matrix](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/MLlibProgrammingGuide/dataTypes/005_RowMatrix)\n        * [Indexed Row Matrix](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/MLlibProgrammingGuide/dataTypes/006_IndexedRowMatrix)\n        * [Coordinate Matrix](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/MLlibProgrammingGuide/dataTypes/007_CoordinateMatrix)\n        * [Block Matrix](#workspace/scalable-data-science/xtraResources/ProgGuides1_6/MLlibProgrammingGuide/dataTypes/008_BlockMatrix)\n    * [Introduction to XML-parsing of Old Bailey Online](#workspace/scalable-data-science/xtraResources/OldBaileyOnline/OBO_LoadExtract)\n","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"980a8f5a-ec8a-4003-8947-86045e58f3c8"}],"dashboards":[],"guid":"5ccea490-07dc-4a89-bb68-e35a62dacdaf","globalVars":{},"iPythonMetadata":null,"inputWidgets":{}};</script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/201606222113370000-29e64bf9afe1117763a990704253c3678448e6c5/js/notebook-main.js"
 onerror="window.mainJsLoadError = true;"></script>
</head>
<body>
  <script>
if (window.mainJsLoadError) {
  var u = 'https://databricks-prod-cloudfront.cloud.databricks.com/static/201606222113370000-29e64bf9afe1117763a990704253c3678448e6c5/js/notebook-main.js';
  var b = document.getElementsByTagName('body')[0];
  var c = document.createElement('div');
  c.innerHTML = ('<h1>Network Error</h1>' +
    '<p><b>Please check your network connection and try again.</b></p>' +
    '<p>Could not load a required resource: ' + u + '</p>');
  c.style.margin = '30px';
  c.style.padding = '20px 50px';
  c.style.backgroundColor = '#f5f5f5';
  c.style.borderRadius = '5px';
  b.appendChild(c);
}
</script>
</body>
</html>
