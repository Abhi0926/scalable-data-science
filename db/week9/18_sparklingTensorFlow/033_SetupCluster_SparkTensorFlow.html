<!DOCTYPE html>
<html>
<head>
  <meta name="databricks-html-version" content="1">
<title>033_SetupCluster_SparkTensorFlow - Databricks</title>

<meta charset="utf-8">
<meta name="google" content="notranslate">
<meta http-equiv="Content-Language" content="en">
<meta http-equiv="Content-Type" content="text/html; charset=UTF8">
<link rel="stylesheet"
  href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700">

<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201602081754420800-0c2673ac858e227cad536fdb45d140aeded238db/lib/css/bootstrap.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201602081754420800-0c2673ac858e227cad536fdb45d140aeded238db/lib/jquery-ui-bundle/jquery-ui.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201602081754420800-0c2673ac858e227cad536fdb45d140aeded238db/css/main.css">
<link rel="stylesheet" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201602081754420800-0c2673ac858e227cad536fdb45d140aeded238db/css/print.css" media="print">
<link rel="icon" type="image/png" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201602081754420800-0c2673ac858e227cad536fdb45d140aeded238db/img/favicon.ico"/>
<script>window.settings = {"sparkDocsSearchGoogleCx":"004588677886978090460:_rj0wilqwdm","dbcForumURL":"http://forums.databricks.com/","dbfsS3Host":"https://databricks-prod-storage-sydney.s3.amazonaws.com","enableThirdPartyApplicationsUI":false,"enableClusterAcls":false,"notebookRevisionVisibilityHorizon":0,"enableTableHandler":true,"isAdmin":true,"enableLargeResultDownload":false,"nameAndEmail":"Raazesh Sainudiin (r.sainudiin@math.canterbury.ac.nz)","enablePresentationTimerConfig":true,"enableFullTextSearch":true,"enableElasticSparkUI":true,"clusters":true,"hideOffHeapCache":false,"applications":false,"useStaticGuide":false,"fileStoreBase":"FileStore","configurableSparkOptionsSpec":[{"keyPattern":"spark\\.kryo(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.kryo.*","valuePatternDisplay":"*","description":"Configuration options for Kryo serialization"},{"keyPattern":"spark\\.io\\.compression\\.codec","valuePattern":"(lzf|snappy|org\\.apache\\.spark\\.io\\.LZFCompressionCodec|org\\.apache\\.spark\\.io\\.SnappyCompressionCodec)","keyPatternDisplay":"spark.io.compression.codec","valuePatternDisplay":"snappy|lzf","description":"The codec used to compress internal data such as RDD partitions, broadcast variables and shuffle outputs."},{"keyPattern":"spark\\.serializer","valuePattern":"(org\\.apache\\.spark\\.serializer\\.JavaSerializer|org\\.apache\\.spark\\.serializer\\.KryoSerializer)","keyPatternDisplay":"spark.serializer","valuePatternDisplay":"org.apache.spark.serializer.JavaSerializer|org.apache.spark.serializer.KryoSerializer","description":"Class to use for serializing objects that will be sent over the network or need to be cached in serialized form."},{"keyPattern":"spark\\.rdd\\.compress","valuePattern":"(true|false)","keyPatternDisplay":"spark.rdd.compress","valuePatternDisplay":"true|false","description":"Whether to compress serialized RDD partitions (e.g. for StorageLevel.MEMORY_ONLY_SER). Can save substantial space at the cost of some extra CPU time."},{"keyPattern":"spark\\.speculation","valuePattern":"(true|false)","keyPatternDisplay":"spark.speculation","valuePatternDisplay":"true|false","description":"Whether to use speculation (recommended off for streaming)"},{"keyPattern":"spark\\.es(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"es(\\.([^\\.]+))+","valuePattern":".*","keyPatternDisplay":"es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"spark\\.(storage|shuffle)\\.memoryFraction","valuePattern":"0?\\.0*([1-9])([0-9])*","keyPatternDisplay":"spark.(storage|shuffle).memoryFraction","valuePatternDisplay":"(0.0,1.0)","description":"Fraction of Java heap to use for Spark's shuffle or storage"},{"keyPattern":"spark\\.streaming\\.backpressure\\.enabled","valuePattern":"(true|false)","keyPatternDisplay":"spark.streaming.backpressure.enabled","valuePatternDisplay":"true|false","description":"Enables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process. Internally, this dynamically sets the maximum receiving rate of receivers. This rate is upper bounded by the values `spark.streaming.receiver.maxRate` and `spark.streaming.kafka.maxRatePerPartition` if they are set."},{"keyPattern":"spark\\.streaming\\.receiver\\.maxRate","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.receiver.maxRate","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which each receiver will receive data. Effectively, each stream will consume at most this number of records per second. Setting this configuration to 0 or a negative number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for mode details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRatePerPartition","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRatePerPartition","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which data will be read from each Kafka partition when using the Kafka direct stream API introduced in Spark 1.3. See the Kafka Integration guide for more details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRetries","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRetries","valuePatternDisplay":"numeric","description":"Maximum number of consecutive retries the driver will make in order to find the latest offsets on the leader of each partition (a default value of 1 means that the driver will make a maximum of 2 attempts). Only applies to the Kafka direct stream API introduced in Spark 1.3."},{"keyPattern":"spark\\.streaming\\.ui\\.retainedBatches","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.ui.retainedBatches","valuePatternDisplay":"numeric","description":"How many batches the Spark Streaming UI and status APIs remember before garbage collecting."}],"enableReactNotebookComments":true,"enableResetPassword":true,"enableJobsSparkUpgrade":true,"sparkVersions":[{"key":"1.3.x-ubuntu15.10","displayName":"Spark 1.3.0","packageLabel":"spark-1.3-jenkins-ip-10-30-9-162-U0c2673ac85-Sa2ee4664b2-2016-02-09-02:05:59.455061","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.4.x-ubuntu15.10","displayName":"Spark 1.4.1","packageLabel":"spark-1.4-jenkins-ip-10-30-9-162-U0c2673ac85-S33a1e4b9c6-2016-02-09-02:05:59.455061","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.5.x-ubuntu15.10","displayName":"Spark 1.5.2","packageLabel":"spark-1.5-jenkins-ip-10-30-9-162-U0c2673ac85-S5917a1044d-2016-02-09-02:05:59.455061","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.x-ubuntu15.10","displayName":"Spark 1.6.0","packageLabel":"spark-1.6-jenkins-ip-10-30-9-162-U0c2673ac85-Scabba801f3-2016-02-09-02:05:59.455061","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"master","displayName":"Spark master (dev)","packageLabel":"","upgradable":true,"deprecated":false,"customerVisible":false}],"enableRestrictedClusterCreation":false,"enableFeedback":false,"defaultNumWorkers":8,"serverContinuationTimeoutMillis":10000,"driverStderrFilePrefix":"stderr","driverStdoutFilePrefix":"stdout","enableSparkDocsSearch":true,"prefetchSidebarNodes":true,"sparkHistoryServerEnabled":true,"sanitizeMarkdownHtml":true,"enableIPythonImportExport":true,"enableNotebookHistoryDiffing":true,"branch":"2.12.3","accountsLimit":-1,"enableNotebookGitBranching":true,"local":false,"displayDefaultContainerMemoryGB":6,"deploymentMode":"production","useSpotForWorkers":false,"enableUserInviteWorkflow":false,"enableStaticNotebooks":true,"dbcGuideURL":"#workspace/databricks_guide/00 Welcome to Databricks","enableCssTransitions":true,"pricingURL":"https://databricks.com/product/pricing","enableClusterAclsConfig":false,"orgId":0,"enableNotebookGitVersioning":true,"files":"files/","enableDriverLogsUI":true,"disableLegacyDashboards":false,"enableWorkspaceAclsConfig":true,"dropzoneMaxFileSize":4096,"enableNewDashboardViews":false,"driverLog4jFilePrefix":"log4j","enableMavenLibraries":true,"displayRowLimit":1000,"defaultSparkVersion":{"key":"1.5.x-ubuntu15.10","displayName":"Spark 1.5.2","packageLabel":"spark-1.5-jenkins-ip-10-30-9-162-U0c2673ac85-S5917a1044d-2016-02-09-02:05:59.455061","upgradable":true,"deprecated":false,"customerVisible":true},"clusterPublisherRootId":5,"enableLatestJobRunResultPermalink":true,"disallowAddingAdmins":false,"enableSparkConfUI":true,"enableOrgSwitcherUI":false,"clustersLimit":-1,"enableJdbcImport":true,"logfiles":"logfiles/","enableWebappSharding":false,"enableClusterDeltaUpdates":true,"csrfToken":"4c37e4ff-a908-4b05-8c61-2b76819fa34c","useFixedStaticNotebookVersionForDevelopment":false,"enableBasicReactDialogBoxes":true,"requireEmailUserName":true,"enableDashboardViews":false,"dbcFeedbackURL":"http://feedback.databricks.com/forums/263785-product-feedback","enableWorkspaceAclService":true,"someName":"Raazesh Sainudiin","enableWorkspaceAcls":true,"gitHash":"0c2673ac858e227cad536fdb45d140aeded238db","userFullname":"Raazesh Sainudiin","enableClusterCreatePage":false,"enableImportFromUrl":true,"enableMiniClusters":false,"enableWebSocketDeltaUpdates":true,"enableDebugUI":false,"showHiddenSparkVersions":false,"allowNonAdminUsers":true,"userId":100005,"dbcSupportURL":"","staticNotebookResourceUrl":"https://databricks-prod-cloudfront.cloud.databricks.com/static/201602081754420800-0c2673ac858e227cad536fdb45d140aeded238db/","enableSparkPackages":true,"enableHybridClusterType":false,"enableNotebookHistoryUI":true,"availableWorkspaces":[{"name":"Workspace 0","orgId":0}],"enableFolderHtmlExport":true,"enableSparkVersionsUI":true,"databricksGuideStaticUrl":"","enableHybridClusters":true,"notebookLoadingBackground":"#fff","enableNewJobRunDetailsPage":true,"enableDashboardExport":true,"user":"r.sainudiin@math.canterbury.ac.nz","enableServerAutoComplete":true,"enableStaticHtmlImport":true,"defaultMemoryPerContainerMB":6000,"enablePresenceUI":true,"tablesPublisherRootId":7,"enableNewInputWidgetUI":false,"accounts":true,"enableNewProgressReportUI":true,"defaultCoresPerContainer":4};</script>
<script>var __DATABRICKS_NOTEBOOK_MODEL = {"version":"NotebookV1","origId":112776,"name":"033_SetupCluster_SparkTensorFlow","language":"python","commands":[{"version":"CommandV1","origId":112906,"guid":"5746119c-01d1-47d6-8cc4-ba206bbe31e0","subtype":"command","commandType":"auto","position":0.5,"command":"%md\n\n# [Scalable Data Science](http://www.math.canterbury.ac.nz/~r.sainudiin/courses/ScalableDataScience/)\n\n\n### prepared by [Paul Brouwers](https://www.linkedin.com/in/paul-brouwers-5365117a), [Raazesh Sainudiin](https://nz.linkedin.com/in/raazesh-sainudiin-45955845) and [Sivanand Sivaram](https://www.linkedin.com/in/sivanand)\n\n*supported by* [![](https://raw.githubusercontent.com/raazesh-sainudiin/scalable-data-science/master/images/databricks_logoTM_200px.png)](https://databricks.com/)\nand \n[![](https://raw.githubusercontent.com/raazesh-sainudiin/scalable-data-science/master/images/AWS_logoTM_200px.png)](https://www.awseducate.com/microsite/CommunitiesEngageHome)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"097caad8-bd49-4cf1-8448-d36e20997029"},{"version":"CommandV1","origId":112907,"guid":"0b225f65-3a80-4c8d-8fdb-46021598d50f","subtype":"command","commandType":"auto","position":0.75,"command":"%md\n** Students of the Scalable Data Science Course at UC, Ilam ** \n\n* First check if a cluster named `classClusterTensorFlow` is running.\n* If it is then just skip this notebook and attach the next notebook to `classClusterTensorFlow`\n","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"687c732b-fab8-43c0-83c7-03542fd35f84"},{"version":"CommandV1","origId":112778,"guid":"49d198af-ca4d-47e1-b244-61b9887bf798","subtype":"command","commandType":"auto","position":1.0,"command":"%md \n## TensorFlow initialization scripts\n\n> This notebook explains how to install TensorFlow on a large cluster. It is __not__ required for the Databricks Community Edition.\n\nThe TensorFlow library needs to be installed directly on all the nodes of the cluster. We show here how to install complex python packages that are not supported yet by the Databricks library manager. Such libraries are directly installed using _cluster initialization scripts_ (\"init scripts\" for short). These scripts are Bash programs that run on a compute node when this node is being added to a cluster.\n\nFor more information, please refer to the init scripts in the Databricks guide.\n\nThese scripts require the name of the cluster. If you use this notebook, you will need to change the name of the cluster in the cell below:","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"a15eb5d7-3ab4-4f23-83b1-59640961ae2c"},{"version":"CommandV1","origId":112779,"guid":"c7322db8-610d-4f5d-aa3f-e0e4c7d8c4e7","subtype":"command","commandType":"auto","position":1.5,"command":"%md\n## Step 1. Set cluster variable and check","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"920a36d1-6551-4ac1-8777-dd4c334b79da"},{"version":"CommandV1","origId":112780,"guid":"77438046-d67a-4089-8938-918e2dfef90c","subtype":"command","commandType":"auto","position":2.0,"command":"# Change the value to the name of your cluster:\nclusterName = \"classClusterTensorFlow\"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"startTime":1.466477299931E12,"submitTime":1.466477088936E12,"finishTime":1.466477300444E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"r.sainudiin@math.canterbury.ac.nz","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"52b3237c-5992-40bb-b485-509a34268153"},{"version":"CommandV1","origId":112781,"guid":"bd268fa1-dbda-4ca4-b15b-8e4e01f0c853","subtype":"command","commandType":"auto","position":2.125,"command":"%md\nTo check if the init scripts are already in this cluster.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"483823d5-f7a9-4f55-9aa7-de7385b25286"},{"version":"CommandV1","origId":112782,"guid":"88bc3901-2813-46c6-8ca1-9be84ccfc71a","subtype":"command","commandType":"auto","position":2.25,"command":"dbutils.fs.ls(\"dbfs:/databricks/init/%s/\" % clusterName)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">2</span><span class=\"ansired\">]: </span>\n[FileInfo(path=u&apos;dbfs:/databricks/init/classClusterTensorFlow/pillow-install.sh&apos;, name=u&apos;pillow-install.sh&apos;, size=200L),\n FileInfo(path=u&apos;dbfs:/databricks/init/classClusterTensorFlow/tensorflow-install.sh&apos;, name=u&apos;tensorflow-install.sh&apos;, size=145L)]\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"java.io.FileNotFoundException: /databricks/init/classClusterTensorFlow","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">ExecutionError</span>                            Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-2-a029a43c9bd8&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>dbutils<span class=\"ansiyellow\">.</span>fs<span class=\"ansiyellow\">.</span>ls<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;dbfs:/databricks/init/%s/&quot;</span> <span class=\"ansiyellow\">%</span> clusterName<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/tmp/1463005161455-0/dbutils.py</span> in <span class=\"ansicyan\">f_with_exception_handling</span><span class=\"ansiblue\">(*args, **kwargs)</span>\n<span class=\"ansigreen\">    116</span>                     <span class=\"ansigreen\">class</span> ExecutionError<span class=\"ansiyellow\">(</span>BaseException<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    117</span>                         <span class=\"ansigreen\">pass</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 118</span><span class=\"ansiyellow\">                     </span><span class=\"ansigreen\">raise</span> ExecutionError<span class=\"ansiyellow\">(</span>str<span class=\"ansiyellow\">(</span>e<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    119</span>             <span class=\"ansigreen\">return</span> f_with_exception_handling<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    120</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">ExecutionError</span>: An error occurred while calling z:com.databricks.backend.daemon.dbutils.FSUtils.ls.\n: java.io.FileNotFoundException: /databricks/init/classClusterTensorFlow\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:63)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:40)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystem.listStatus(DatabricksFileSystem.scala:174)\n\tat com.databricks.backend.daemon.dbutils.FSUtils$.ls(DBUtilsCore.scala:60)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.ls(DBUtilsCore.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\n\n</div>","startTime":1.466477301768E12,"submitTime":1.466477090915E12,"finishTime":1.466477303189E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"r.sainudiin@math.canterbury.ac.nz","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"4d7fff26-9352-4676-bf8e-99b2a687e1aa"},{"version":"CommandV1","origId":133228,"guid":"e30e3492-1243-487e-be94-e01935289c12","subtype":"command","commandType":"auto","position":2.34375,"command":"%md\nIf ``pillow-install.sh` and `tensorflow-install.sh` are already in this cluster then skip **Step 2** below.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"7b6f3d2e-0ceb-49e4-8390-0012e6fdfa67"},{"version":"CommandV1","origId":112783,"guid":"a60c5e30-1bd0-4b1d-876f-294c59cfe04e","subtype":"command","commandType":"auto","position":2.4375,"command":"%md\n## Step 2. To (re)create init scripts\n\nIf the `.sh` files above are not there, then evaluate the cell below and restart the cluster.\n\n**Sub-step 2.1**","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"fdccadd4-1f46-49b6-991e-d03720d07fb6"},{"version":"CommandV1","origId":112784,"guid":"90f5da38-ad2b-4317-ae34-f2333e0edb12","subtype":"command","commandType":"auto","position":2.5,"command":"%md \nThe following commands create init scripts that install the TensorFlow library on your cluster whenever it gets started or restarted. If you do not want to have TensorFlow installed on this cluster by default, you need to remove the scripts, by running the following command:\n\n  ```python\n  dbutils.fs.rm(\"dbfs:/databricks/init/%s/tensorflow-install.sh\" % clusterName)\n  dbutils.fs.rm(\"dbfs:/databricks/init/%s/pillow-install.sh\" % clusterName)\n  ```","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"b796908b-4292-4709-8f1d-a6b8fd42f2a0"},{"version":"CommandV1","origId":112785,"guid":"29cb533e-0c8f-451b-97bc-2555d4679e5a","subtype":"command","commandType":"auto","position":3.0,"command":"%md \nThe next cell creates the init scripts. You need to restart your cluster after running the following command.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"2ce9efbb-82b0-4863-a52c-1fb985eefc87"},{"version":"CommandV1","origId":112786,"guid":"5091f870-4063-45b2-8d11-1035d1471bb8","subtype":"command","commandType":"auto","position":4.0,"command":"dbutils.fs.mkdirs(\"dbfs:/databricks/init/\")\ndbutils.fs.put(\"dbfs:/databricks/init/%s/tensorflow-install.sh\" % clusterName,\"\"\"\n#!/bin/bash \n/databricks/python/bin/pip install https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.6.0-cp27-none-linux_x86_64.whl\n\"\"\", True)\n\n# This is just to get nice image visualization\ndbutils.fs.put(\"dbfs:/databricks/init/%s/pillow-install.sh\" % clusterName,\"\"\"\n#!/bin/bash \necho \"------ packages --------\"\nsudo apt-get -y --force-yes install libtiff5-dev libjpeg8-dev zlib1g-dev\necho \"------ python packages --------\"\n/databricks/python/bin/pip install pillow\n\"\"\", True)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Wrote 145 bytes.\nWrote 200 bytes.\n<span class=\"ansired\">Out[</span><span class=\"ansired\">3</span><span class=\"ansired\">]: </span>True\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"startTime":1.463005168071E12,"submitTime":1.463005025374E12,"finishTime":1.463005169593E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"paul.brouwers@canterbury.ac.nz","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"ed6b1d6d-b1ea-41c9-90b6-0fc3f07fd1f6"},{"version":"CommandV1","origId":112787,"guid":"5f26b2db-1913-4fb8-bd41-8d03929a6a9f","subtype":"command","commandType":"auto","position":5.0,"command":"%md \n**Sub-step 2.2** You now need to restart your cluster.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"25ef92dc-3dd7-435c-8526-0a6a4063ff73"},{"version":"CommandV1","origId":112788,"guid":"f6b6a742-4a2e-4e9c-965e-acfd4b920d60","subtype":"command","commandType":"auto","position":6.0,"command":"%md \n## 3. How to check that the scripts ran correctly after running a cluster (possibly by restarting)\n\nAs explained in the Databricks guide, the output of init scripts is stored in DBFS. The following cell accesses the latest content of the logs after a cluster start:","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"a28e5e0f-7f63-4c43-99e9-7be2d9fad7c3"},{"version":"CommandV1","origId":112789,"guid":"bb325fe3-e5a8-43c6-90c9-38a6a1db8086","subtype":"command","commandType":"auto","position":7.0,"command":"stamp = str(dbutils.fs.ls(\"/databricks/init/output/%s/\" % clusterName)[-1].name)\nprint(\"Stamp is %s\" % stamp)\nfiles = dbutils.fs.ls(\"/databricks/init/output/%s/%s\" % (clusterName, str(stamp)))\ntf_files = [str(fi.path) for fi in files if fi.name.startswith(\"%s-tensorflow-install\" % clusterName)]\nlogs = [dbutils.fs.head(fname) for fname in tf_files]\nfor log in logs:\n  print \"************************\"\n  print log","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Stamp is 2016-06-20_03-47-57/\n************************\nstdout:\nDownloading/unpacking https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.6.0-cp27-none-linux_x86_64.whl\nDownloading/unpacking six&gt;=1.10.0 (from tensorflow==0.6.0)\n  Downloading six-1.10.0-py2.py3-none-any.whl\nDownloading/unpacking protobuf==3.0.0a3 (from tensorflow==0.6.0)\n  Running setup.py (path:/tmp/pip-build-TQbOzE/protobuf/setup.py) egg_info for package protobuf\n    \n    no previously-included directories found matching &apos;google/protobuf/internal/import_test_package&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_pb2.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_test.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*.proto&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/test_util.py&apos;\n    warning: no previously-included files matching &apos;*_test.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*_test.proto&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;unittest*_pb2.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*.dll&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyc&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyo&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.so&apos; found anywhere in distribution\nDownloading/unpacking wheel (from tensorflow==0.6.0)\nRequirement already satisfied (use --upgrade to upgrade): numpy&gt;=1.8.2 in /usr/lib/python2.7/dist-packages (from tensorflow==0.6.0)\nRequirement already satisfied (use --upgrade to upgrade): setuptools in /databricks/python/lib/python2.7/site-packages (from protobuf==3.0.0a3-&gt;tensorflow==0.6.0)\nInstalling collected packages: tensorflow, six, protobuf, wheel\n  Found existing installation: six 1.5.2\n    Uninstalling six:\n      Successfully uninstalled six\n  Running setup.py install for protobuf\n    Skipping installation of /databricks/python/lib/python2.7/site-packages/google/__init__.py (namespace package)\n    \n    no previously-included directories found matching &apos;google/protobuf/internal/import_test_package&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_pb2.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_test.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*.proto&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/test_util.py&apos;\n    warning: no previously-included files matching &apos;*_test.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*_test.proto&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;unittest*_pb2.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*.dll&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyc&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyo&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.so&apos; found anywhere in distribution\n    Installing /databricks/python/lib/python2.7/site-packages/protobuf-3.0.0a3-py2.7-nspkg.pth\nSuccessfully installed tensorflow six protobuf wheel\nCleaning up...\n\nstderr:\n\n************************\nstdout:\nDownloading/unpacking https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.6.0-cp27-none-linux_x86_64.whl\nDownloading/unpacking six&gt;=1.10.0 (from tensorflow==0.6.0)\n  Downloading six-1.10.0-py2.py3-none-any.whl\nDownloading/unpacking protobuf==3.0.0a3 (from tensorflow==0.6.0)\n  Running setup.py (path:/tmp/pip-build-CitCpr/protobuf/setup.py) egg_info for package protobuf\n    \n    no previously-included directories found matching &apos;google/protobuf/internal/import_test_package&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_pb2.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_test.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*.proto&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/test_util.py&apos;\n    warning: no previously-included files matching &apos;*_test.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*_test.proto&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;unittest*_pb2.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*.dll&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyc&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyo&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.so&apos; found anywhere in distribution\nDownloading/unpacking wheel (from tensorflow==0.6.0)\nRequirement already satisfied (use --upgrade to upgrade): numpy&gt;=1.8.2 in /usr/lib/python2.7/dist-packages (from tensorflow==0.6.0)\nRequirement already satisfied (use --upgrade to upgrade): setuptools in /databricks/python/lib/python2.7/site-packages (from protobuf==3.0.0a3-&gt;tensorflow==0.6.0)\nInstalling collected packages: tensorflow, six, protobuf, wheel\n  Found existing installation: six 1.5.2\n    Uninstalling six:\n      Successfully uninstalled six\n  Running setup.py install for protobuf\n    Skipping installation of /databricks/python/lib/python2.7/site-packages/google/__init__.py (namespace package)\n    \n    no previously-included directories found matching &apos;google/protobuf/internal/import_test_package&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_pb2.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_test.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*.proto&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/test_util.py&apos;\n    warning: no previously-included files matching &apos;*_test.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*_test.proto&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;unittest*_pb2.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*.dll&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyc&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyo&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.so&apos; found anywhere in distribution\n    Installing /databricks/python/lib/python2.7/site-packages/protobuf-3.0.0a3-py2.7-nspkg.pth\nSuccessfully installed tensorflow six protobuf wheel\nCleaning up...\n\nstderr:\n\n************************\nstdout:\nDownloading/unpacking https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.6.0-cp27-none-linux_x86_64.whl\nDownloading/unpacking six&gt;=1.10.0 (from tensorflow==0.6.0)\n  Downloading six-1.10.0-py2.py3-none-any.whl\nDownloading/unpacking protobuf==3.0.0a3 (from tensorflow==0.6.0)\n  Running setup.py (path:/tmp/pip-build-0TnpTq/protobuf/setup.py) egg_info for package protobuf\n    \n    no previously-included directories found matching &apos;google/protobuf/internal/import_test_package&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_pb2.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_test.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*.proto&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/test_util.py&apos;\n    warning: no previously-included files matching &apos;*_test.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*_test.proto&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;unittest*_pb2.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*.dll&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyc&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyo&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.so&apos; found anywhere in distribution\nDownloading/unpacking wheel (from tensorflow==0.6.0)\nRequirement already satisfied (use --upgrade to upgrade): numpy&gt;=1.8.2 in /usr/lib/python2.7/dist-packages (from tensorflow==0.6.0)\nRequirement already satisfied (use --upgrade to upgrade): setuptools in /databricks/python/lib/python2.7/site-packages (from protobuf==3.0.0a3-&gt;tensorflow==0.6.0)\nInstalling collected packages: tensorflow, six, protobuf, wheel\n  Found existing installation: six 1.5.2\n    Uninstalling six:\n      Successfully uninstalled six\n  Running setup.py install for protobuf\n    Skipping installation of /databricks/python/lib/python2.7/site-packages/google/__init__.py (namespace package)\n    \n    no previously-included directories found matching &apos;google/protobuf/internal/import_test_package&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_pb2.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_test.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*.proto&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/test_util.py&apos;\n    warning: no previously-included files matching &apos;*_test.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*_test.proto&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;unittest*_pb2.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*.dll&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyc&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyo&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.so&apos; found anywhere in distribution\n    Installing /databricks/python/lib/python2.7/site-packages/protobuf-3.0.0a3-py2.7-nspkg.pth\nSuccessfully installed tensorflow six protobuf wheel\nCleaning up...\n\nstderr:\n\n************************\nstdout:\nDownloading/unpacking https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.6.0-cp27-none-linux_x86_64.whl\nDownloading/unpacking six&gt;=1.10.0 (from tensorflow==0.6.0)\n  Downloading six-1.10.0-py2.py3-none-any.whl\nDownloading/unpacking protobuf==3.0.0a3 (from tensorflow==0.6.0)\n  Running setup.py (path:/tmp/pip-build-U2KkRb/protobuf/setup.py) egg_info for package protobuf\n    \n    no previously-included directories found matching &apos;google/protobuf/internal/import_test_package&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_pb2.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_test.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*.proto&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/test_util.py&apos;\n    warning: no previously-included files matching &apos;*_test.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*_test.proto&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;unittest*_pb2.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*.dll&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyc&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyo&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.so&apos; found anywhere in distribution\nDownloading/unpacking wheel (from tensorflow==0.6.0)\nRequirement already satisfied (use --upgrade to upgrade): numpy&gt;=1.8.2 in /usr/lib/python2.7/dist-packages (from tensorflow==0.6.0)\nRequirement already satisfied (use --upgrade to upgrade): setuptools in /databricks/python/lib/python2.7/site-packages (from protobuf==3.0.0a3-&gt;tensorflow==0.6.0)\nInstalling collected packages: tensorflow, six, protobuf, wheel\n  Found existing installation: six 1.5.2\n    Uninstalling six:\n      Successfully uninstalled six\n  Running setup.py install for protobuf\n    Skipping installation of /databricks/python/lib/python2.7/site-packages/google/__init__.py (namespace package)\n    \n    no previously-included directories found matching &apos;google/protobuf/internal/import_test_package&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_pb2.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_test.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*.proto&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/test_util.py&apos;\n    warning: no previously-included files matching &apos;*_test.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*_test.proto&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;unittest*_pb2.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*.dll&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyc&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyo&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.so&apos; found anywhere in distribution\n    Installing /databricks/python/lib/python2.7/site-packages/protobuf-3.0.0a3-py2.7-nspkg.pth\nSuccessfully installed tensorflow six protobuf wheel\nCleaning up...\n\nstderr:\n\n************************\nstdout:\nDownloading/unpacking https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.6.0-cp27-none-linux_x86_64.whl\nDownloading/unpacking six&gt;=1.10.0 (from tensorflow==0.6.0)\n  Downloading six-1.10.0-py2.py3-none-any.whl\nDownloading/unpacking protobuf==3.0.0a3 (from tensorflow==0.6.0)\n  Running setup.py (path:/tmp/pip-build-BLzREI/protobuf/setup.py) egg_info for package protobuf\n    \n    no previously-included directories found matching &apos;google/protobuf/internal/import_test_package&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_pb2.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_test.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*.proto&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/test_util.py&apos;\n    warning: no previously-included files matching &apos;*_test.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*_test.proto&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;unittest*_pb2.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*.dll&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyc&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyo&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.so&apos; found anywhere in distribution\nDownloading/unpacking wheel (from tensorflow==0.6.0)\nRequirement already satisfied (use --upgrade to upgrade): numpy&gt;=1.8.2 in /usr/lib/python2.7/dist-packages (from tensorflow==0.6.0)\nRequirement already satisfied (use --upgrade to upgrade): setuptools in /databricks/python/lib/python2.7/site-packages (from protobuf==3.0.0a3-&gt;tensorflow==0.6.0)\nInstalling collected packages: tensorflow, six, protobuf, wheel\n  Found existing installation: six 1.5.2\n    Uninstalling six:\n      Successfully uninstalled six\n  Running setup.py install for protobuf\n    Skipping installation of /databricks/python/lib/python2.7/site-packages/google/__init__.py (namespace package)\n    \n    no previously-included directories found matching &apos;google/protobuf/internal/import_test_package&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_pb2.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_test.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*.proto&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/test_util.py&apos;\n    warning: no previously-included files matching &apos;*_test.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*_test.proto&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;unittest*_pb2.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*.dll&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyc&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyo&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.so&apos; found anywhere in distribution\n    Installing /databricks/python/lib/python2.7/site-packages/protobuf-3.0.0a3-py2.7-nspkg.pth\nSuccessfully installed tensorflow six protobuf wheel\nCleaning up...\n\nstderr:\n\n************************\nstdout:\nDownloading/unpacking https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.6.0-cp27-none-linux_x86_64.whl\nDownloading/unpacking six&gt;=1.10.0 (from tensorflow==0.6.0)\n  Downloading six-1.10.0-py2.py3-none-any.whl\nDownloading/unpacking protobuf==3.0.0a3 (from tensorflow==0.6.0)\n  Running setup.py (path:/tmp/pip-build-uI4BrK/protobuf/setup.py) egg_info for package protobuf\n    \n    no previously-included directories found matching &apos;google/protobuf/internal/import_test_package&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_pb2.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_test.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*.proto&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/test_util.py&apos;\n    warning: no previously-included files matching &apos;*_test.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*_test.proto&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;unittest*_pb2.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*.dll&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyc&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyo&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.so&apos; found anywhere in distribution\nDownloading/unpacking wheel (from tensorflow==0.6.0)\nRequirement already satisfied (use --upgrade to upgrade): numpy&gt;=1.8.2 in /usr/lib/python2.7/dist-packages (from tensorflow==0.6.0)\nRequirement already satisfied (use --upgrade to upgrade): setuptools in /databricks/python/lib/python2.7/site-packages (from protobuf==3.0.0a3-&gt;tensorflow==0.6.0)\nInstalling collected packages: tensorflow, six, protobuf, wheel\n  Found existing installation: six 1.5.2\n    Uninstalling six:\n      Successfully uninstalled six\n  Running setup.py install for protobuf\n    Skipping installation of /databricks/python/lib/python2.7/site-packages/google/__init__.py (namespace package)\n    \n    no previously-included directories found matching &apos;google/protobuf/internal/import_test_package&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_pb2.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_test.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*.proto&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/test_util.py&apos;\n    warning: no previously-included files matching &apos;*_test.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*_test.proto&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;unittest*_pb2.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*.dll&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyc&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyo&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.so&apos; found anywhere in distribution\n    Installing /databricks/python/lib/python2.7/site-packages/protobuf-3.0.0a3-py2.7-nspkg.pth\nSuccessfully installed tensorflow six protobuf wheel\nCleaning up...\n\nstderr:\n\n************************\nstdout:\nDownloading/unpacking https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.6.0-cp27-none-linux_x86_64.whl\nDownloading/unpacking six&gt;=1.10.0 (from tensorflow==0.6.0)\n  Downloading six-1.10.0-py2.py3-none-any.whl\nDownloading/unpacking protobuf==3.0.0a3 (from tensorflow==0.6.0)\n  Running setup.py (path:/tmp/pip-build-Js_ib7/protobuf/setup.py) egg_info for package protobuf\n    \n    no previously-included directories found matching &apos;google/protobuf/internal/import_test_package&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_pb2.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_test.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*.proto&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/test_util.py&apos;\n    warning: no previously-included files matching &apos;*_test.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*_test.proto&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;unittest*_pb2.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*.dll&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyc&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyo&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.so&apos; found anywhere in distribution\nDownloading/unpacking wheel (from tensorflow==0.6.0)\nRequirement already satisfied (use --upgrade to upgrade): numpy&gt;=1.8.2 in /usr/lib/python2.7/dist-packages (from tensorflow==0.6.0)\nRequirement already satisfied (use --upgrade to upgrade): setuptools in /databricks/python/lib/python2.7/site-packages (from protobuf==3.0.0a3-&gt;tensorflow==0.6.0)\nInstalling collected packages: tensorflow, six, protobuf, wheel\n  Found existing installation: six 1.5.2\n    Uninstalling six:\n      Successfully uninstalled six\n  Running setup.py install for protobuf\n    Skipping installation of /databricks/python/lib/python2.7/site-packages/google/__init__.py (namespace package)\n    \n    no previously-included directories found matching &apos;google/protobuf/internal/import_test_package&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_pb2.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_test.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*.proto&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/test_util.py&apos;\n    warning: no previously-included files matching &apos;*_test.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*_test.proto&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;unittest*_pb2.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*.dll&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyc&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyo&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.so&apos; found anywhere in distribution\n    Installing /databricks/python/lib/python2.7/site-packages/protobuf-3.0.0a3-py2.7-nspkg.pth\nSuccessfully installed tensorflow six protobuf wheel\nCleaning up...\n\nstderr:\n\n************************\nstdout:\nDownloading/unpacking https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.6.0-cp27-none-linux_x86_64.whl\nDownloading/unpacking six&gt;=1.10.0 (from tensorflow==0.6.0)\n  Downloading six-1.10.0-py2.py3-none-any.whl\nDownloading/unpacking protobuf==3.0.0a3 (from tensorflow==0.6.0)\n  Running setup.py (path:/tmp/pip-build-3GY7q7/protobuf/setup.py) egg_info for package protobuf\n    \n    no previously-included directories found matching &apos;google/protobuf/internal/import_test_package&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_pb2.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_test.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*.proto&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/test_util.py&apos;\n    warning: no previously-included files matching &apos;*_test.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*_test.proto&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;unittest*_pb2.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*.dll&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyc&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyo&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.so&apos; found anywhere in distribution\nDownloading/unpacking wheel (from tensorflow==0.6.0)\nRequirement already satisfied (use --upgrade to upgrade): numpy&gt;=1.8.2 in /usr/lib/python2.7/dist-packages (from tensorflow==0.6.0)\nRequirement already satisfied (use --upgrade to upgrade): setuptools in /databricks/python/lib/python2.7/site-packages (from protobuf==3.0.0a3-&gt;tensorflow==0.6.0)\nInstalling collected packages: tensorflow, six, protobuf, wheel\n  Found existing installation: six 1.5.2\n    Uninstalling six:\n      Successfully uninstalled six\n  Running setup.py install for protobuf\n    Skipping installation of /databricks/python/lib/python2.7/site-packages/google/__init__.py (namespace package)\n    \n    no previously-included directories found matching &apos;google/protobuf/internal/import_test_package&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_pb2.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_test.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*.proto&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/test_util.py&apos;\n    warning: no previously-included files matching &apos;*_test.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*_test.proto&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;unittest*_pb2.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*.dll&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyc&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyo&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.so&apos; found anywhere in distribution\n    Installing /databricks/python/lib/python2.7/site-packages/protobuf-3.0.0a3-py2.7-nspkg.pth\nSuccessfully installed tensorflow six protobuf wheel\nCleaning up...\n\nstderr:\n\n************************\nstdout:\nDownloading/unpacking https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.6.0-cp27-none-linux_x86_64.whl\nDownloading/unpacking six&gt;=1.10.0 (from tensorflow==0.6.0)\n  Downloading six-1.10.0-py2.py3-none-any.whl\nDownloading/unpacking protobuf==3.0.0a3 (from tensorflow==0.6.0)\n  Running setup.py (path:/tmp/pip-build-r5eQsg/protobuf/setup.py) egg_info for package protobuf\n    \n    no previously-included directories found matching &apos;google/protobuf/internal/import_test_package&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_pb2.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_test.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*.proto&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/test_util.py&apos;\n    warning: no previously-included files matching &apos;*_test.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*_test.proto&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;unittest*_pb2.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*.dll&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyc&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyo&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.so&apos; found anywhere in distribution\nDownloading/unpacking wheel (from tensorflow==0.6.0)\nRequirement already satisfied (use --upgrade to upgrade): numpy&gt;=1.8.2 in /usr/lib/python2.7/dist-packages (from tensorflow==0.6.0)\nRequirement already satisfied (use --upgrade to upgrade): setuptools in /databricks/python/lib/python2.7/site-packages (from protobuf==3.0.0a3-&gt;tensorflow==0.6.0)\nInstalling collected packages: tensorflow, six, protobuf, wheel\n  Found existing installation: six 1.5.2\n    Uninstalling six:\n      Successfully uninstalled six\n  Running setup.py install for protobuf\n    Skipping installation of /databricks/python/lib/python2.7/site-packages/google/__init__.py (namespace package)\n    \n    no previously-included directories found matching &apos;google/protobuf/internal/import_test_package&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_pb2.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*_test.py&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/*.proto&apos;\n    warning: no previously-included files found matching &apos;google/protobuf/internal/test_util.py&apos;\n    warning: no previously-included files matching &apos;*_test.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*_test.proto&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;unittest*_pb2.py&apos; found under directory &apos;google&apos;\n    warning: no previously-included files matching &apos;*.dll&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyc&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.pyo&apos; found anywhere in distribution\n    warning: no previously-included files matching &apos;*.so&apos; found anywhere in distribution\n    Installing /databricks/python/lib/python2.7/site-packages/protobuf-3.0.0a3-py2.7-nspkg.pth\nSuccessfully installed tensorflow six protobuf wheel\nCleaning up...\n\nstderr:\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"<span class=\"ansired\">NameError</span>: name &apos;clusterName&apos; is not defined","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-1-4b1c5f81f505&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>stamp <span class=\"ansiyellow\">=</span> str<span class=\"ansiyellow\">(</span>dbutils<span class=\"ansiyellow\">.</span>fs<span class=\"ansiyellow\">.</span>ls<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;/databricks/init/output/%s/&quot;</span> <span class=\"ansiyellow\">%</span> clusterName<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansiyellow\">-</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">.</span>name<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      2</span> <span class=\"ansigreen\">print</span><span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;Stamp is %s&quot;</span> <span class=\"ansiyellow\">%</span> stamp<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      3</span> files <span class=\"ansiyellow\">=</span> dbutils<span class=\"ansiyellow\">.</span>fs<span class=\"ansiyellow\">.</span>ls<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;/databricks/init/output/%s/%s&quot;</span> <span class=\"ansiyellow\">%</span> <span class=\"ansiyellow\">(</span>clusterName<span class=\"ansiyellow\">,</span> str<span class=\"ansiyellow\">(</span>stamp<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      4</span> tf_files <span class=\"ansiyellow\">=</span> <span class=\"ansiyellow\">[</span>str<span class=\"ansiyellow\">(</span>fi<span class=\"ansiyellow\">.</span>path<span class=\"ansiyellow\">)</span> <span class=\"ansigreen\">for</span> fi <span class=\"ansigreen\">in</span> files <span class=\"ansigreen\">if</span> fi<span class=\"ansiyellow\">.</span>name<span class=\"ansiyellow\">.</span>startswith<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;%s-tensorflow-install&quot;</span> <span class=\"ansiyellow\">%</span> clusterName<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      5</span> logs <span class=\"ansiyellow\">=</span> <span class=\"ansiyellow\">[</span>dbutils<span class=\"ansiyellow\">.</span>fs<span class=\"ansiyellow\">.</span>head<span class=\"ansiyellow\">(</span>fname<span class=\"ansiyellow\">)</span> <span class=\"ansigreen\">for</span> fname <span class=\"ansigreen\">in</span> tf_files<span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: name &apos;clusterName&apos; is not defined\n</div>","startTime":1.466395028535E12,"submitTime":1.46639481923E12,"finishTime":1.466395030966E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"r.sainudiin@math.canterbury.ac.nz","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"8908f47e-b0f5-4a25-8578-64c682a0fb1f"},{"version":"CommandV1","origId":112790,"guid":"4d0b17f8-1bdd-4ad0-b4a5-3df17569d4a7","subtype":"command","commandType":"auto","position":8.0,"command":"%md\n\n# [Scalable Data Science](http://www.math.canterbury.ac.nz/~r.sainudiin/courses/ScalableDataScience/)\n\n\n### prepared by [Paul Brouwers](https://www.linkedin.com/in/paul-brouwers-5365117a), [Raazesh Sainudiin](https://nz.linkedin.com/in/raazesh-sainudiin-45955845) and [Sivanand Sivaram](https://www.linkedin.com/in/sivanand)\n\n*supported by* [![](https://raw.githubusercontent.com/raazesh-sainudiin/scalable-data-science/master/images/databricks_logoTM_200px.png)](https://databricks.com/)\nand \n[![](https://raw.githubusercontent.com/raazesh-sainudiin/scalable-data-science/master/images/AWS_logoTM_200px.png)](https://www.awseducate.com/microsite/CommunitiesEngageHome)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"0d2a93d6-97db-40a2-aa0c-627c9dedbf9b"}],"dashboards":[],"guid":"56c50aed-7168-4eaa-9b50-9ce8c4a135bf","globalVars":{},"iPythonMetadata":null,"inputWidgets":{}};</script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/201602081754420800-0c2673ac858e227cad536fdb45d140aeded238db/js/notebook-main.js"
 onerror="window.mainJsLoadError = true;"></script>
</head>
<body>
  <script>
if (window.mainJsLoadError) {
  var u = 'https://databricks-prod-cloudfront.cloud.databricks.com/static/201602081754420800-0c2673ac858e227cad536fdb45d140aeded238db/js/notebook-main.js';
  var b = document.getElementsByTagName('body')[0];
  var c = document.createElement('div');
  c.innerHTML = ('<h1>Network Error</h1>' +
    '<p><b>Please check your network connection and try again.</b></p>' +
    '<p>Could not load a required resource: ' + u + '</p>');
  c.style.margin = '30px';
  c.style.padding = '20px 50px';
  c.style.backgroundColor = '#f5f5f5';
  c.style.borderRadius = '5px';
  b.appendChild(c);
}
</script>
</body>
</html>
