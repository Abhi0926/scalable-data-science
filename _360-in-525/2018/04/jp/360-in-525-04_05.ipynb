{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Random Variables, Expectations, Data, Statistics, Arrays and Tuples\n",
    "## [Mathematical Statistical and Computational Foundations for Data Scientists](https://lamastex.github.io/scalable-data-science/360-in-525/2018/04/)\n",
    "\n",
    "&copy;2018 Raazesh Sainudiin. [Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics\n",
    "\n",
    "1. Continuous Random Variables\n",
    "- Expectations\n",
    "- Data and Statistics\n",
    "- Sample Mean\n",
    "- Sample Variance\n",
    "- Order Statistics\n",
    "- Frequencies\n",
    "- Empirical Mass Function\n",
    "- Empirical Distribution Function\n",
    "- Arrays\n",
    "- Tuples\n",
    " \n",
    "\n",
    "# Random Variables\n",
    "\n",
    "A random variable is a mapping from the sample space $\\Omega$ to the set of real numbers $\\mathbb{R}$.  In other words, it is a numerical value determined by the outcome of the experiment.\n",
    "\n",
    "We already saw *discrete random variables* that take values in a discrete set, of two types:\n",
    "\n",
    "- those with with finitely many values, eg. the two values in $\\{0,1\\}$ for the Bernoulli$(\\theta)$ RV \n",
    "- those with *countably infinitely many* values, eg. values in the set of all non-negative integers: $\\{0,1,2,\\ldots\\}$, for the 'infinite coin tossing experiment' that records the number of times you wait until the first Heads occurs.\n",
    "\n",
    "Now, we will see the other main type of real-valued random variable.\n",
    "\n",
    "## Continuous random variable\n",
    "\n",
    "When a random variable takes on values in the continuum we call it a continuous RV.\n",
    "\n",
    "### Examples\n",
    "\n",
    "- Volume of water that fell on the Southern Alps yesterday (See video link below)\n",
    "- Vertical position above sea level, in micrometers, since the original release of a pollen grain at the head waters of a river\n",
    "- Resting position in degrees of a roulettet wheel after a brisk spin\n",
    "\n",
    "## Probability Density Function\n",
    "\n",
    "A RV $X$ with DF $F$ is called continuous if there exists a piece-wise continuous function $f$, called the  probability density function (PDF) $f$ of $X$, such that, for any $a$, $b \\in \\mathbb{R}$ with $a < b$,\n",
    "\n",
    "$$\n",
    "P(a < X \\le b) = F(b)-F(a) = \\int_a^b f(x) \\ dx \\ .\n",
    "$$\n",
    "\n",
    "\n",
    "The following hold for a continuous RV $X$ with PDF $f$:\n",
    "\n",
    "For any $x \\in \\mathbb{R}$, $P(X=x)=0$.\n",
    "Consequentially, for any $a,b \\in \\mathbb{R}$ with $a \\le b$ \n",
    "$$P(a < X < b ) = P(a < X \\le b) = P(a \\leq X \\le b) = P(a \\le X < b)$$\n",
    "By the fundamental theorem of calculus, except possibly at finitely many points (where the continuous pieces come together in the piecewise-continuous $f$): \n",
    "$$f(x) = \\frac{d}{dx} F(x)$$\n",
    "And of course $f$ must satisfy:\n",
    "$$\\int_{-\\infty}^{\\infty} f(x) \\ dx = P(-\\infty < X < \\infty) = 1$$\n",
    "\n",
    "\n",
    "### You try at home\n",
    "Watch the Khan Academy [video about probability density functions](https://youtu.be/Fvi9A_tEmXQ) to warm-up to the meaning behind the maths above. Consider the continuous random variable $Y$ that measures the exact amount of rain tomorrow in inches. Think of the probability space $(\\Omega,\\mathcal{F},P)$ underpinning this random variable $Y:\\Omega \\to \\mathbb{Y}$. Here the sample space, range or support of the random variable $Y$ denoted by $\\mathbb{Y} = [0,\\infty) =\\{y : 0 \\leq y < \\infty\\}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Uniform$(0,1)$ RV\n",
    "\n",
    "The Uniform$(0,1)$ RV is a continuous RV with a probability density function (PDF) that takes the value 1 if $x \\in [0,1]$ and $0$ otherwise.  Formally, this is written  \n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "f(x) = \\mathbf{1}_{[0,1]}(x) =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } 0 \\le x \\le 1 ,\\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "and its distribution function (DF) or cumulative distribution function (CDF) is:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "F(x) := \\int_{- \\infty}^x f(y) \\ dy =\n",
    "\\begin{cases}\n",
    "0 & \\text{if } x < 0 , \\\\\n",
    "x & \\text{if } 0 \\le x \\leq 1 ,\\\\\n",
    "1 & \\text{if } x > 1\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "Note that the DF is the identity map in $[0,1]$. \n",
    "\n",
    "The PDF, CDF and inverse CDF for a Uniform$(0,1)$ RV are shown below\n",
    "\n",
    "<img src=\"images/Uniform01ThreeCharts.png\" alt=\"Uniform01ThreeCharts\" width=500>\n",
    "\n",
    "The Uniform$(0,1)$ is sometimes called the Fundamental Model.\n",
    "\n",
    "The Uniform$(0,1)$ distribution comes from the Uniform$(a,b)$ family.   \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "f(x) = \\mathbf{1}_{[a,b]}(x) =\n",
    "\\begin{cases}\n",
    "\\frac{1}{(b-a)} & \\text{if } a \\le x \\le b,\\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "This is saying that if $X$ is a Uniform$(a,b)$ RV, then all values of $x$ between $a$ and $b$, i.e., $a \\le x \\le b$, are equally probable.   The Uniform$(0,1)$ RV is the member of the family where $a=0$, $b=1$.    \n",
    "\n",
    " The PDF and CDF for a Uniform$(a,b)$ RV are shown from wikipedia below\n",
    "\n",
    "<table style=\"width:95%\">\n",
    "  <tr>\n",
    "    <th><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/96/Uniform_Distribution_PDF_SVG.svg/500px-Uniform_Distribution_PDF_SVG.svg.png\" alt=\"500px-Uniform_Distribution_PDF_SVG.svg.png\" width=250></th>\n",
    "    <th><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Uniform_cdf.svg/500px-Uniform_cdf.svg.png\" alt=\"wikipedia image 500px-Uniform_cdf.svg.png\" width=250></th> \n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "You can dive deeper into this family of random vaiables <a href=\"https://en.wikipedia.org/wiki/Uniform_distribution_(continuous)\">here</a>.\n",
    "\n",
    "SageMath has a function for simulating samples from a Uniform$(a,b)$ distribution.  We will learn more about this later in the course. Let's go ahead and use it to simulate samples from it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.15206205043245413"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform(-1,1)  # reevaluate the cell to see how the samples change upon each re-evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectations\n",
    "\n",
    "The *expectation* of $X$ is also known as the *population mean*, *first moment*, or *expected value* of $X$.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "E\\left(X\\right) := \\int x \\, dF(x) =\n",
    "\\begin{cases}\n",
    "\\sum_x x \\, f(x) & \\qquad \\text{if }X \\text{ is discrete} \\\\\n",
    "\\int x \\, f(x)\\,dx  & \\qquad \\text{if } X \\text{ is continuous}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Sometimes, we denote $E(X)$ by $E X$ for brevity.  Thus, the expectation is a single-number summary of the RV $X$ and may be thought of  as the average.\n",
    "\n",
    "In general though, we can talk about the Expectation of a function $g$ of a RV $X$.  \n",
    "\n",
    "The Expectation of a function $g$ of a RV $X$ with DF $F$ is:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "E\\left(g(X)\\right) := \\int g(x)\\,dF(x) =\n",
    "\\begin{cases}\n",
    "\\sum_x g(x) f(x) & \\qquad \\text{if }X \\text{ is discrete} \\\\\n",
    "\\int g(x) f(x)\\,dx  & \\qquad \\text{if } X \\text{ is continuous}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "provided the sum or integral is well-defined.  We say the expectation exists if\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\int \\left|g(x)\\right|\\,dF(x) < \\infty \\ .\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "When we are looking at the Expectation of $X$ itself, we have $g(x) = x$\n",
    "\n",
    "Thinking about the Expectations like this, can you see that the familiar Variance of X is in fact the Expection of $g(x) = (x - E(x))^2$?\n",
    "\n",
    "The variance of $X$ (a.k.a. second moment)\n",
    "\n",
    "Let $X$ be a RV with mean or expectation $E(X)$.  The variance of $X$ denoted by $V(X)$ or $VX$ is\n",
    "\n",
    "$$\n",
    "V(X) := E\\left((X-E(X))^2\\right) = \\int (x-E(X))^2 \\,d F(x)\n",
    "$$\n",
    "\n",
    "provided this expectation exists.  The standard deviation denoted by $\\sigma(X) := \\sqrt{V(X)}$.\n",
    "\n",
    "Thus variance is a measure of ``spread'' of a distribution.\n",
    "\n",
    "The $k$-th moment of a RV comes from the Expectation of $g(x) = x^k$.\n",
    "\n",
    "We call\n",
    "\n",
    "$$\n",
    "E(X^k) = \\int x^k\\,dF(x)\n",
    "$$\n",
    "\n",
    "\n",
    "the $k$-th moment of the RV $X$ and say that the $k$-th moment exists when $E(|X|^k) < \\infty$.  \n",
    "\n",
    "\n",
    "## Properties of Expectations\n",
    "\n",
    "\n",
    "\n",
    "1. If the $k$-th moment exists and if $j<k$ then the $j$-th moment exists.\n",
    "- If $X_1,X_2,\\ldots,X_n$ are RVs and $a_1,a_2,\\ldots,a_n$ are constants, then $E \\left( \\sum_{i=1}^n a_i X_i \\right) = \\sum_{i=1}^n a_i E(X_i)$\n",
    "- Let $X_1,X_2,\\ldots,X_n$ be independent RVs, then \n",
    "  - $E \\left(  \\prod_{i=1}^n X_i \\right) = \\prod_{i=1}^{n} E(X_i)$\n",
    "  - $V(X) = E(X^2) - (E(X))^2$\n",
    "- If $a$ and $b$ are constants, then: $V \\left(aX + b\\right) = a^2V(X) $\n",
    "- If $X_1,X_2,\\ldots,X_n$ are independent and $a_1,a_2,\\ldots,a_n$ are constants, then: $V \\left(  \\sum_{i=1}^n a_i X_i \\right) = \\sum_{i=1}^n a_i^2 V(X_i)$\n",
    "\n",
    "### You try at home\n",
    "\n",
    "Watch the Khan Academy videos about [probability density functions](https://youtu.be/Fvi9A_tEmXQ) and [expected value](https://youtu.be/j__Kredt7vY) if you want to get another angle on the material more slowly step-by-step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 8.1",
   "language": "",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
